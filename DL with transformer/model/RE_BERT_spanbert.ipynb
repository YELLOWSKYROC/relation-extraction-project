{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21332,"status":"ok","timestamp":1709751088201,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":0},"id":"Y5yej-1ovufz","outputId":"fd0fa30a-e83a-4d46-8c6a-bc241c5a75fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/Drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/Drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16636,"status":"ok","timestamp":1709751104832,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":0},"id":"nanNQZCEMHDO","outputId":"d2d31295-4016-46fd-ac4b-e5594200759f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n"]}],"source":["!pip install torch torchvision torchaudio\n","!pip install transformers\n","!pip install tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4NHSnwIXv0na"},"outputs":[],"source":["import json\n","import random\n","import warnings\n","import torch\n","import time\n","import argparse\n","import json\n","import os\n","import time\n","import copy\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import torch.nn.functional\n","\n","\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import MinMaxScaler\n","from transformers import BertForSequenceClassification, BertTokenizer, BertModel, AdamW"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709751112171,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":0},"id":"yeH_1AYRDb8U","outputId":"37e5a8b4-bcab-47a7-ca09-82c8142f260b"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'no_relation': 0, 'per:title': 1, 'org:top_members/employees': 2, 'org:country_of_headquarters': 3, 'per:parents': 4, 'per:age': 5, 'per:countries_of_residence': 6, 'per:children': 7, 'org:alternate_names': 8, 'per:charges': 9, 'per:cities_of_residence': 10, 'per:origin': 11, 'org:founded_by': 12, 'per:employee_of': 13, 'per:siblings': 14, 'per:alternate_names': 15, 'org:website': 16, 'per:religion': 17, 'per:stateorprovince_of_death': 18, 'org:parents': 19, 'org:subsidiaries': 20, 'per:other_family': 21, 'per:stateorprovinces_of_residence': 22, 'org:members': 23, 'per:cause_of_death': 24, 'org:member_of': 25, 'org:number_of_employees/members': 26, 'per:country_of_birth': 27, 'org:shareholders': 28, 'org:stateorprovince_of_headquarters': 29, 'per:city_of_death': 30, 'per:date_of_birth': 31, 'per:spouse': 32, 'org:city_of_headquarters': 33, 'per:date_of_death': 34, 'per:schools_attended': 35, 'org:political/religious_affiliation': 36, 'per:country_of_death': 37, 'org:founded': 38, 'per:stateorprovince_of_birth': 39, 'per:city_of_birth': 40, 'org:dissolved': 41}\n","{0: 'no_relation', 1: 'per:title', 2: 'org:top_members/employees', 3: 'org:country_of_headquarters', 4: 'per:parents', 5: 'per:age', 6: 'per:countries_of_residence', 7: 'per:children', 8: 'org:alternate_names', 9: 'per:charges', 10: 'per:cities_of_residence', 11: 'per:origin', 12: 'org:founded_by', 13: 'per:employee_of', 14: 'per:siblings', 15: 'per:alternate_names', 16: 'org:website', 17: 'per:religion', 18: 'per:stateorprovince_of_death', 19: 'org:parents', 20: 'org:subsidiaries', 21: 'per:other_family', 22: 'per:stateorprovinces_of_residence', 23: 'org:members', 24: 'per:cause_of_death', 25: 'org:member_of', 26: 'org:number_of_employees/members', 27: 'per:country_of_birth', 28: 'org:shareholders', 29: 'org:stateorprovince_of_headquarters', 30: 'per:city_of_death', 31: 'per:date_of_birth', 32: 'per:spouse', 33: 'org:city_of_headquarters', 34: 'per:date_of_death', 35: 'per:schools_attended', 36: 'org:political/religious_affiliation', 37: 'per:country_of_death', 38: 'org:founded', 39: 'per:stateorprovince_of_birth', 40: 'per:city_of_birth', 41: 'org:dissolved'}\n"]}],"source":["# List of relation types\n","keys = ['no_relation', 'per:title', 'org:top_members/employees',\n","        'org:country_of_headquarters', 'per:parents', 'per:age',\n","        'per:countries_of_residence', 'per:children', 'org:alternate_names',\n","        'per:charges', 'per:cities_of_residence', 'per:origin', 'org:founded_by',\n","        'per:employee_of', 'per:siblings', 'per:alternate_names', 'org:website',\n","        'per:religion', 'per:stateorprovince_of_death', 'org:parents',\n","        'org:subsidiaries', 'per:other_family', 'per:stateorprovinces_of_residence',\n","        'org:members', 'per:cause_of_death', 'org:member_of',\n","        'org:number_of_employees/members', 'per:country_of_birth',\n","        'org:shareholders', 'org:stateorprovince_of_headquarters',\n","        'per:city_of_death', 'per:date_of_birth', 'per:spouse',\n","        'org:city_of_headquarters', 'per:date_of_death', 'per:schools_attended',\n","        'org:political/religious_affiliation', 'per:country_of_death',\n","        'org:founded', 'per:stateorprovince_of_birth', 'per:city_of_birth',\n","        'org:dissolved']\n","\n","# Assigning indices to the list elements and storing them in a dictionary\n","rel2id = {key: idx for idx, key in enumerate(keys)}\n","id2rel = {idx: key for key, idx in rel2id.items()}\n","\n","# Printing the dictionaries\n","print(rel2id)\n","print(id2rel)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1709751112836,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":0},"id":"Welvz8AbMHDR","outputId":"046b55d9-237d-42e6-9057-16bd3f6d2fb9"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n","using GPU\n"]}],"source":["# tell pytorch to use the gpu if available\n","if torch.cuda.is_available():\n","\n","    DEVICE = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    DEVICE = torch.device(\"cpu\")\n","\n","USE_CUDA = torch.cuda.is_available()\n","if USE_CUDA:\n","    print(\"using GPU\")\n","else:\n","    print(\"using CPU\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2503,"status":"ok","timestamp":1709751115334,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":0},"id":"R5bbj5oeMHDS","outputId":"dacb98ce-ebdf-43df-f245-129642d330c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["BERT tokenizer loaded\n"]}],"source":["#BERT tokenizer\n","model_directory = '/content/Drive/MyDrive/COMP61332_text_mining/RE/Tacred/Bert_RE/span-bert/spanbert-base-cased'\n","tokenizer = BertTokenizer.from_pretrained(model_directory)\n","# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n","print('BERT tokenizer loaded')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6No8Wu6SN95j"},"outputs":[],"source":["def setup_seed(seed):\n","    # Sets the seed for generating random numbers for the CPU.\n","\n","    # Sets the seed for generating random numbers for all GPUs.\n","    torch.cuda.manual_seed_all(seed)\n","\n","    # Sets the seed for generating random numbers with NumPy.\n","    np.random.seed(seed)\n","\n","    # Sets the seed for the built-in Python random module.\n","    random.seed(seed)\n","\n","setup_seed(44)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xTmRuAmIv04k"},"outputs":[],"source":["def load_tacred_dataset(file_path):\n","    \"\"\"\n","    Load the TACRED dataset from a JSON file.\n","\n","    Args:\n","    file_path (str): The path to the JSON file containing the dataset.\n","\n","    Returns:\n","    dict: The loaded dataset.\n","    \"\"\"\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vLsXtBwYv1EN"},"outputs":[],"source":["def prepare_data(data):\n","    # Get the number of instances in the data\n","    n = len(data)\n","\n","    # Initialize an empty list to store processed data\n","    info = []\n","\n","    # Iterate through each instance in the data\n","    for i in range(n):\n","        # Initialize an empty dictionary for storing processed information of a single data instance\n","        single_data = {}\n","\n","        # Extract start and end indices of subject and object entities\n","        ss = data[i][\"subj_start\"]\n","        se = data[i][\"subj_end\"]\n","        os = data[i][\"obj_start\"]\n","        oe = data[i][\"obj_end\"]\n","\n","        # Extract subject and object tokens based on their start and end indices\n","        subj = data[i]['token'][ss: se+1]\n","        obj = data[i]['token'][os: oe+1]\n","\n","        # Convert subject and object tokens into strings\n","        ent1 = ' '.join(subj)\n","        ent2 = ' '.join(obj)\n","\n","        # Extract relation label\n","        rel = data[i][\"relation\"]\n","\n","        # Concatenate all tokens to form the original sentence\n","        text = \" \".join(data[i][\"token\"])\n","\n","        # Store processed information in the dictionary\n","        single_data['rel'] = rel\n","        single_data['ent1'] = ent1\n","        single_data['ent2'] = ent2\n","        single_data['text'] = text\n","\n","        # Append processed information of a single data instance to the list\n","        info.append(single_data)\n","\n","    # Return the processed data\n","    return info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pD96gM1FDb--"},"outputs":[],"source":["def process_relation_extraction_data(info, max_length=64):\n","    # Initialize a dictionary to store processed data\n","    data = {}\n","    data['label'] = []  # List to store relation labels\n","    data['mask'] = []   # List to store attention masks\n","    data['text'] = []   # List to store tokenized and padded texts\n","\n","    # Iterate through each instance in the provided 'info' data\n","    for line in info:\n","        # Check if the relation label is present in the 'rel2id' dictionary\n","        if line['rel'] not in rel2id:\n","            # If the relation label is not found, assign label 0 (for unknown relation)\n","            data['label'].append(0)\n","        else:\n","            # If the relation label is found, assign its corresponding index\n","            data['label'].append(rel2id[line['rel']])\n","\n","        # Concatenate subject, object, and text to form a single sentence\n","        sent = line['ent1'] + line['ent2'] + line['text']\n","\n","        # Tokenize the concatenated sentence and add special tokens\n","        indexed_tokens = tokenizer.encode(sent, add_special_tokens=True)\n","\n","        # Determine the available length of the tokenized sentence\n","        avai_len = len(indexed_tokens)\n","\n","        # Pad the tokenized sentence with 0s to match the maximum length\n","        while len(indexed_tokens) < max_length:\n","            indexed_tokens.append(0)\n","\n","        # Trim the tokenized sentence to the maximum length\n","        indexed_tokens = indexed_tokens[:max_length]\n","\n","        # Convert the tokenized sentence to a PyTorch tensor\n","        indexed_tokens = torch.tensor(indexed_tokens).long().unsqueeze(0)  # (1, L)\n","\n","        # Create an attention mask for the tokenized sentence\n","        att_mask = torch.zeros(indexed_tokens.size()).long()  # (1, L)\n","        att_mask[0, :avai_len] = 1\n","\n","        # Append the tokenized and padded sentence, and its attention mask to the data dictionary\n","        data['text'].append(indexed_tokens)\n","        data['mask'].append(att_mask)\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTsJ6q_dMHDW"},"outputs":[],"source":["def convert_data_to_tensors(data):\n","    # Extract text, mask, and label from the data\n","    text = data['text']\n","    mask = data['mask']\n","    label = data['label']\n","\n","    # Convert text and mask tensors to numpy arrays\n","    text = [t.numpy() for t in text]\n","    mask = [t.numpy() for t in mask]\n","\n","    # Convert numpy arrays to PyTorch tensors\n","    text = torch.tensor(text)\n","    mask = torch.tensor(mask)\n","    label = torch.tensor(label)\n","\n","    return text, mask, label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14427,"status":"ok","timestamp":1709751129755,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":0},"id":"6BasTmByTlLF","outputId":"6ad8c049-b794-4a60-b80e-58d603a7c72c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","Some weights of BertModel were not initialized from the model checkpoint at /content/Drive/MyDrive/COMP61332_text_mining/RE/Tacred/Bert_RE/span-bert/spanbert-base-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BERT_Classifier(\n","  (encoder): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (fc): Linear(in_features=768, out_features=42, bias=True)\n","  (criterion): CrossEntropyLoss()\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["class BERT_Classifier(nn.Module):\n","    def __init__(self, label_num):\n","        super().__init__()\n","        # Initialize the BERT encoder from pre-trained weights\n","        # self.encoder = BertModel.from_pretrained('bert-base-uncased')\n","        model_directory = '/content/Drive/MyDrive/COMP61332_text_mining/RE/Tacred/Bert_RE/span-bert/spanbert-base-cased'\n","\n","        # Load the tokenizer and model\n","        self.encoder = BertModel.from_pretrained(model_directory)\n","        # Dropout layer to prevent overfitting\n","        self.dropout = nn.Dropout(0.1, inplace=False)\n","        # Fully connected layer for classification\n","        self.fc = nn.Linear(768, label_num)  # 768 is the hidden size of BERT\n","        # Cross-entropy loss criterion\n","        self.criterion = nn.CrossEntropyLoss()\n","\n","    def forward(self, x, attention_mask, label=None):\n","        # Pass the input through the BERT encoder\n","        x = self.encoder(x, attention_mask=attention_mask)[0]  # Output is tuple (last_hidden_state, pooler_output), we take the last_hidden_state\n","        # Take only the first token's output (CLS token)\n","        x = x[:, 0, :]\n","        # Apply dropout\n","        x = self.dropout(x)\n","        # Pass through the fully connected layer\n","        x = self.fc(x)\n","        # If label is not provided, return logits only\n","        if label is None:\n","            return None, x\n","        else:\n","            # Calculate the cross-entropy loss and return both loss and logits\n","            return self.criterion(x, label), x\n","\n","labels_num=len(rel2id)\n","# print(labels_num)\n","model = BERT_Classifier(labels_num)\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qAyTlPuuU_7m"},"outputs":[],"source":["def train(net, train_dataset, dev_dataset, num_epochs, learning_rate, batch_size):\n","\n","    print('Training...')\n","\n","    # Set the network to training mode\n","    net.train()\n","\n","    # Define the optimizer\n","    optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n","\n","    # Create a data loader for training data\n","    train_iter = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n","\n","    for epoch in range(num_epochs):\n","        correct = 0\n","        total = 0\n","        iter = 0\n","        all_pred = []\n","        all_true = []\n","\n","        # Initialize tqdm to show progress bar\n","        progress_bar = tqdm(train_iter, desc=f'Epoch {epoch + 1}/{num_epochs}', unit='batch')\n","\n","        for text, mask, y in progress_bar:\n","            iter += 1\n","            optimizer.zero_grad()\n","\n","            # If the batch size is not equal to the specified batch size, break the loop\n","            if text.size(0) != batch_size:\n","                break\n","\n","            # Reshape text and mask tensors\n","            text = text.reshape(batch_size, -1)\n","            mask = mask.reshape(batch_size, -1)\n","\n","            # Move tensors to GPU if available\n","            if USE_CUDA:\n","                text = text.cuda()\n","                mask = mask.cuda()\n","                y = y.cuda()\n","\n","            # Forward pass\n","            loss, logits = net(text, mask, y)\n","\n","            # Backpropagation\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Compute accuracy\n","            _, predicted = torch.max(logits.data, 1)\n","            total += text.size(0)\n","            correct += predicted.data.eq(y.data).cpu().sum()\n","\n","            # Collect predictions and true labels\n","            all_pred.extend(predicted.cpu().numpy())\n","            all_true.extend(y.cpu().numpy())\n","\n","            # Update progress bar\n","            progress_bar.set_postfix({'loss': loss.item(), 'accuracy': correct.item() / total})\n","\n","        # After the end of each epoch, compute metrics\n","        accuracy = correct.cpu().numpy().tolist()/total\n","        loss = loss.detach().cpu()\n","\n","        # Compute F1 scores\n","        macro_f1 = f1_score(all_true, all_pred, average='macro')\n","        micro_f1 = f1_score(all_true, all_pred, average='micro')\n","        weighted_f1 = f1_score(all_true, all_pred, average='weighted')\n","\n","        # Print metrics\n","        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","        print(f\"Loss: {loss.mean().numpy().tolist()}, Accuracy: {accuracy}\")\n","        print(f\"Macro F1: {macro_f1}, Micro F1: {micro_f1}, Weighted F1: {weighted_f1}\")\n","\n","        # print()\n","\n","        # print(\"Validation...\")\n","\n","        # dev_acc, dev_macro_f1, dev_micro_f1, dev_weighted_f1, _, _ = eval(net, dev_dataset, batch_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RRLfrySsMHDX"},"outputs":[],"source":["\n","def eval(net, dataset, batch_size):\n","    # Set the network to evaluation mode\n","    net.eval()\n","\n","    # Create an iterator for the evaluation dataset\n","    eval_iter = DataLoader(dataset, batch_size, shuffle=False)\n","\n","    # Lists to store predictions and true labels\n","    all_pred = []\n","    all_true = []\n","\n","    # Lists to store evaluation metrics\n","    acc_list = []\n","    macro_f1_list = []\n","    micro_f1_list = []\n","    weighted_f1_list = []\n","    precision_list = []  # List for precision scores\n","    recall_list = []     # List for recall scores\n","\n","    with torch.no_grad():\n","        correct = 0  # Counter for correctly classified samples\n","        total = 0    # Counter for total samples\n","        # Progress bar for visualization during evaluation\n","        progress_bar = tqdm(eval_iter, desc='Evaluation', unit='batch')\n","\n","        for text, mask, y in progress_bar:\n","            if text.size(0) != batch_size:\n","                break\n","\n","            text = text.reshape(batch_size, -1)\n","            mask = mask.reshape(batch_size, -1)\n","\n","            if USE_CUDA:\n","                text, mask, y = text.cuda(), mask.cuda(), y.cuda()\n","\n","            outputs = net(text, mask)\n","            loss, logits = outputs if isinstance(outputs, tuple) else (None, outputs)\n","\n","            _, predicted = torch.max(logits, 1)\n","            total += y.size(0)\n","            correct += (predicted == y).sum().item()\n","\n","            all_pred.extend(predicted.cpu().numpy())\n","            all_true.extend(y.cpu().numpy())\n","\n","        # Calculate overall accuracy and F1 scores\n","        acc = correct / total\n","        macro_f1 = f1_score(all_true, all_pred, average='macro')\n","        micro_f1 = f1_score(all_true, all_pred, average='micro')\n","        weighted_f1 = f1_score(all_true, all_pred, average='weighted')\n","\n","        # Calculate precision and recall\n","        precision_macro = precision_score(all_true, all_pred, average='macro')\n","        recall_macro = recall_score(all_true, all_pred, average='macro')\n","        precision_micro = precision_score(all_true, all_pred, average='micro')\n","        recall_micro = recall_score(all_true, all_pred, average='micro')\n","        precision_weighted = precision_score(all_true, all_pred, average='weighted')\n","        recall_weighted = recall_score(all_true, all_pred, average='weighted')\n","\n","        # Append metrics to respective lists\n","        acc_list.append(acc)\n","        macro_f1_list.append(macro_f1)\n","        micro_f1_list.append(micro_f1)\n","        weighted_f1_list.append(weighted_f1)\n","        precision_list.append((precision_macro, precision_micro, precision_weighted))\n","        recall_list.append((recall_macro, recall_micro, recall_weighted))\n","\n","        # Print evaluation results\n","        print(f\"Eval Result: Acc: {acc:.4f}, Macro F1: {macro_f1:.4f}, Micro F1: {micro_f1:.4f}, Weighted F1: {weighted_f1:.4f}\")\n","        print(f\"Precision (Macro, Micro, Weighted): {precision_macro:.4f}, {precision_micro:.4f}, {precision_weighted:.4f}\")\n","        print(f\"Recall (Macro, Micro, Weighted): {recall_macro:.4f}, {recall_micro:.4f}, {recall_weighted:.4f}\")\n","\n","        # Return evaluation metrics\n","        return acc_list, macro_f1_list, micro_f1_list, weighted_f1_list, precision_list, recall_list\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GxJrdSDTv07h"},"outputs":[],"source":["# Load data from JSON file\n","train_data = load_tacred_dataset('/content/Drive/MyDrive/COMP61332_text_mining/RE/Tacred/json/train.json')\n","dev_data = load_tacred_dataset('/content/Drive/MyDrive/COMP61332_text_mining/RE/Tacred/json/dev.json')\n","test_data = load_tacred_dataset('/content/Drive/MyDrive/COMP61332_text_mining/RE/Tacred/json/test.json')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":755,"status":"ok","timestamp":1709662166551,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":0},"id":"MN2PJFW2v1HN","outputId":"b6513527-ec65-43f1-8bba-8974f7ec9b2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["68124\n","22631\n","15509\n","[{'rel': 'per:title', 'ent1': 'Douglas Flint', 'ent2': 'chairman', 'text': 'At the same time , Chief Financial Officer Douglas Flint will become chairman , succeeding Stephen Green who is leaving to take a government job .'}, {'rel': 'no_relation', 'ent1': 'Julius Baer', 'ent2': 'Jeffrey White', 'text': 'U.S. District Court Judge Jeffrey White in mid-February issued an injunction against Wikileaks after the Zurich-based Bank Julius Baer accused the site of posting sensitive account information stolen by a disgruntled former employee .'}, {'rel': 'per:city_of_death', 'ent1': 'Montcourt', 'ent2': 'PARIS', 'text': 'PARIS 2009-07-07 11:07:32 UTC French media earlier reported that Montcourt , ranked 119 , was found dead by his girlfriend in the stairwell of his Paris apartment .'}, {'rel': 'no_relation', 'ent1': 'Freedom Communications', 'ent2': 'current', 'text': 'The current holdings of Blackstone-operated funds include Universal Orlando , Cadbury Schweppes , Freedom Communications , Nielsen Co. , Orangina and Vanguard Health Systems .'}, {'rel': 'no_relation', 'ent1': 'Girija Prashad Koirala', 'ent2': 'Nepali', 'text': \"The ICDC was formed after the Nepali government and the guerrillas reached in an understanding during summit talks held on July 16 at Prime Minister Girija Prashad Koirala 's residence at Baluwatar in downtown Kathmandu city .\"}, {'rel': 'no_relation', 'ent1': 'IARC', 'ent2': 'Murray', 'text': 'http://groups.yahoo.com/group/aspartameNM/message/1417 formaldehyde as a potent unexamined cofactor in cancer research -- sources include methanol , dark wines and liquors , aspartame , wood and tobacco smoke : IARC Monographs on the Evaluation of Carcinogenic Risks to Humans implicate formaldehyde in # 88 and alcohol drinks in # 96 : some related abstracts : Murray 2007.05.15'}, {'rel': 'org:shareholders', 'ent1': 'Burlington Northern Santa Fe Corp.', 'ent2': 'his', 'text': 'Warren Buffett , who committed most of his Berkshire Hathaway Inc. shares to charity , is speeding the pace at which he reduces his ownership stake with the $ 26 billion takeover of railroad Burlington Northern Santa Fe Corp. .'}, {'rel': 'no_relation', 'ent1': 'Bobby Frankel', 'ent2': 'U.S. Hall of Fame', 'text': \"`` She made a devastating run around the turn , '' U.S. Hall of Fame trainer Bobby Frankel said .\"}, {'rel': 'per:origin', 'ent1': 'Claude Chabrol', 'ent2': 'French', 'text': 'Prolific French film maker Claude Chabrol , who helped start the New Wave movement in the 1950s , died on Sunday aged 80 , Paris deputy mayor Christophe Girard told AFP .'}, {'rel': 'per:city_of_death', 'ent1': 'Mohammed Oudeh', 'ent2': 'Damascus', 'text': 'The self-declared mastermind of the attack , Mohammed Oudeh , better known by his guerrilla name , Abu Daoud , died last month in Damascus at age 73 .'}, {'rel': 'no_relation', 'ent1': 'Bobby Frankel', 'ent2': 'Monday', 'text': 'Bobby Frankel , one of the most successful American thoroughbred trainers of the last 40 years , whose horses included the champions Bertrando , Ghostzapper and Empire Maker , the winner of the 2003 Belmont Stakes , died Monday at his home in Pacific Palisades , Calif. .'}, {'rel': 'org:top_members/employees', 'ent1': 'Indoor Tanning Association', 'ent2': 'John Overstreet', 'text': \"John Overstreet , executive director of the Indoor Tanning Association , says this of dermatologists who are critical of tanning beds : `` They love to talk about skin cancer ; they love to scare everyone to death . ''\"}, {'rel': 'no_relation', 'ent1': 'Rose', 'ent2': 'his', 'text': 'There has been much uncertainty surrounding the future of Rose , whose success in turning the group around following his appointment in 2004 has tailed off in recent months causing the M and S share price to slide .'}, {'rel': 'no_relation', 'ent1': 'Stockholm International Peace Research Institute', 'ent2': 'Siemon Wezeman', 'text': \"Siemon Wezeman of the Stockholm International Peace Research Institute said issues of `` national prestige '' have always blocked efforts to resolve the dispute and warned that further militarisation carried obvious dangers .\"}, {'rel': 'no_relation', 'ent1': 'his', 'ent2': 'Rod Dedeaux', 'text': 'When he was 8 , his family moved to Los Angeles , and he became a batboy for the University of Southern California teams coached by Rod Dedeaux , one of the best-known figures in college baseball .'}, {'rel': 'org:city_of_headquarters', 'ent1': 'Thomas More Law Center', 'ent2': 'Ann Arbor', 'text': \"`` Americans have a right to know the truth -- Islam is a religion of intolerance and violence , '' said Richard Thompson , legal director of the Thomas More Law Center in Ann Arbor .\"}, {'rel': 'no_relation', 'ent1': 'Mike Penner', 'ent2': '1', 'text': \"When Los Angeles Times sportswriter Mike Penner disclosed in a recent column that he 'd be changing his name to Christine Daniels , the piece quickly became the No. 1 draw on the newspaper 's Web site .\"}, {'rel': 'per:religion', 'ent1': 'Benoit B Mandelbrot', 'ent2': 'Jewish', 'text': 'Benoit B Mandelbrot -LRB- he added the middle initial himself , though it does not stand for a middle name -RRB- was born on Nov 20 , 1924 , to a Lithuanian Jewish family in Warsaw , Poland .'}, {'rel': 'no_relation', 'ent1': 'A123 Systems', 'ent2': 'Fisker', 'text': 'A123 Systems , a Massachusetts-based company , has hired 250 workers in the Livonia plant and already has signed contracts with Navistar and Fisker to supply advanced batteries for their electric vehicles after receiving $ 249 million in federal stimulus money .'}, {'rel': 'no_relation', 'ent1': 'IARC', 'ent2': '1987', 'text': 'IARC classified p-dichlorobenzene as a 2B | > substance , possibly carcinogenic to humans , carcinogen -LSB- IARC 1987 -RSB- .'}, {'rel': 'per:city_of_birth', 'ent1': 'Kissel', 'ent2': 'Adrian', 'text': 'Kissel was born in Adrian , Michigan , but her family had also lived in Minneapolis .'}, {'rel': 'no_relation', 'ent1': 'Rosoboronexport', 'ent2': 'he', 'text': 'Kalashnikov is still active and prolific -- he tours the world as a Rosoboronexport consultant helping strike new arms deals , and has penned several books on his life , about arms and about youth education .'}, {'rel': 'no_relation', 'ent1': 'United Steelworkers', 'ent2': 'United Auto Workers', 'text': \"The company 's two biggest unions , the United Auto Workers and the United Steelworkers , have threatened to strike if the company carries out that plan .\"}, {'rel': 'no_relation', 'ent1': 'Nuclear Energy Institute', 'ent2': '1998', 'text': \"TASSC 's executive director from 1997 to 1998 was Steven Milloy , a Washington policy wonk who has rotated through a variety of anti- environmental organizations as well as the EOP Group , a prominent lobby firm whose clients have included the Petroleum Institute , AT&T , the Business Roundtable , the Chlorine Chemistry Council , Dow Chemical , Edison Electric Institute , International Food Additives Council , Monsanto and the Nuclear Energy Institute .\"}, {'rel': 'per:employee_of', 'ent1': 'Anwar Chowdhry', 'ent2': 'PBF', 'text': 'The sports ministry has asked PSB to submit a report on the corruption scandals against Anwar Chowdhry who is the chief of PBF , the secretary of Pakistani sports ministry , Syed Bilal Ahmed said , falling short of giving a deadline of the submission .'}, {'rel': 'no_relation', 'ent1': 'SASAC', 'ent2': 'Administration Commission', 'text': \"According to statistics provided by China 's State-owned Assets Supervision and Administration Commission -LRB- SASAC -RRB- , China had nearly 120,000 state-owned enterprises -LRB- SOE -RRB- , including enterprises or companies with sole state ownership , and joint - venture companies with the state as biggest shareholders , which possessed assets worth more than 9,700 billion yuan -LRB- about 1,330 billion U.S. dollars -RRB- in 2006 .\"}, {'rel': 'no_relation', 'ent1': 'A123 Systems Inc.', 'ent2': 'September 2009', 'text': 'Shares of another green-technology company , lithium-ion battery maker A123 Systems Inc. , gained 50 percent in their market debut on September 2009 .'}, {'rel': 'no_relation', 'ent1': 'Orlando Zapata Tamayo', 'ent2': 'last month', 'text': \"Cuba 's human rights record has come into sharp focus since the death of dissident hunger striker Orlando Zapata Tamayo last month drew international condemnation .\"}, {'rel': 'no_relation', 'ent1': 'STX Finland', 'ent2': '8,500', 'text': \"Last year , STX Finland delivered the world 's largest cruise liner to Royal Caribbean with 2,700 cabins that can accommodate up to 8,500 people .\"}, {'rel': 'org:city_of_headquarters', 'ent1': 'Stockholm International Peace Research Institute', 'ent2': 'STOCKHOLM', 'text': 'STOCKHOLM , Nov 10 -LRB- Xinhua -RRB- - The United States and Russia are by far the largest suppliers of combat aircraft accounting for two - thirds of all combat aircraft delivered in the period 2005-2009 while India is are the largest buyers , according to a report released Wednesday by the Stockholm International Peace Research Institute -LRB- SIPRI -RRB- .'}, {'rel': 'no_relation', 'ent1': 'he', 'ent2': '1987', 'text': 'After several years spent largely at the Centre National de la Recherche Scientifique in Paris , Mandelbrot was hired by IBM in 1958 to work at the Thomas J. Watson Research Center in Yorktown Heights , N.Y. Although he worked frequently with academic researchers and served as a visiting professor at Harvard and the Massachusetts Institute of Technology , it was not until 1987 that he began to teach at Yale , where he earned tenure in 1999 .'}, {'rel': 'per:date_of_death', 'ent1': 'Orlando Zapata', 'ent2': 'February 23', 'text': 'The Cuban government has accused the United States and the European Union of waging a smear campaign against the revolution in the wake of the death of Orlando Zapata , a dissident who died February 23 after a prison hunger strike .'}, {'rel': 'no_relation', 'ent1': 'Public Library of Science', 'ent2': '7', 'text': 'PLoS Biology , 2009 ; 7 -LRB- 3 -RRB- : e61 DOI : 10.1371 / journal.pbio .1000061 Adapted from materials provided by Public Library of Science , via EurekAlert !'}, {'rel': 'no_relation', 'ent1': 'STX Finland', 'ent2': 'Turku', 'text': \"Finnish shipyard STX Finland said Tuesday it will lay off up to 400 workers at the Turku shipyard where it last month completed the construction of the world 's biggest cruise liner .\"}, {'rel': 'per:other_family', 'ent1': 'him', 'ent2': 'Yehudi Menuhin', 'text': \"The violinist Yehudi Menuhin , who brought Khan to the United States in 1955 , called him `` an absolute genius '' and `` the greatest musician in the world . ''\"}, {'rel': 'no_relation', 'ent1': 'her', 'ent2': 'Shilpa Shetty', 'text': \"Goody 's appearance on the show came 18 months after she was accused of racism on British TV 's `` Celebrity Big Brother '' due to her taunting of Bollywood actress and fellow contestant Shilpa Shetty .\"}, {'rel': 'org:top_members/employees', 'ent1': 'Baer', 'ent2': 'Boris Collardi', 'text': 'Boris Collardi , chief executive of Baer , said the deal would strengthen its ties to central and eastern Europe , as well as to Russia .'}, {'rel': 'no_relation', 'ent1': 'Mandelbrot', 'ent2': 'he', 'text': 'A professor emeritus at Yale University , Mandelbrot was born in Poland but as a child moved with his family to France where he was educated .'}, {'rel': 'no_relation', 'ent1': 'Paul Gray', 'ent2': 'Grammy-winning', 'text': 'Paul Gray , the bassist for Grammy-winning metal band Slipknot , was found dead Monday in an Iowa hotel room but there was no indication of foul play , police said .'}, {'rel': 'no_relation', 'ent1': 'Champalimaud', 'ent2': 'he', 'text': 'The private foundation was created when Champalimaud bequeathed a quarter of his -LRB- EURO -RRB- 2 billion -LRB- $ 2.43 billion -RRB- estate when he died in 2004 .'}, {'rel': 'org:website', 'ent1': 'Public Library of Science', 'ent2': 'http://wwwplosorg', 'text': 'Public Library of Science : http://wwwplosorg Named Seitaad ruessi , the species was 10-to-15 feet -LRB- 3 to 45 meters -RRB- long and 3-to-4 feet -LRB- 091 meters to 12 meters -RRB- high .'}, {'rel': 'no_relation', 'ent1': 'Irish Nationwide', 'ent2': 'EURO', 'text': 'The Central Bank announced that another state-seized Dublin lender , Irish Nationwide , also will receive -LRB- EURO -RRB- 2.7 billion more , doubling the amount already spent by the government to keep it afloat .'}, {'rel': 'no_relation', 'ent1': 'his', 'ent2': 'he', 'text': \"The justices also said the trial judge erred in allowing one of Robert Kissel 's friends and a private detective he hired to testify that he expressed worries that his wife may be plotting his murder .\"}, {'rel': 'no_relation', 'ent1': 'her', 'ent2': 'she', 'text': \"I absolutely detest how she 's airing every aspect of her cancer in the public domain -LRB- and do n't bother telling me she 's doing it to raise public awareness -RRB- .\"}, {'rel': 'no_relation', 'ent1': 'Intercontinental Hotels Group', 'ent2': 'PA', 'text': 'Description : Housekeeping SupervisorHI Philadelphia-Historic DistrictUS - PA - Philadelphia Email this job to a friend Job Details Job Description : Description At Intercontinental Hotels Group , we own , operate and franchise more than 3500 hotels , offering close to half a million guest rooms in nearly 100 countries .'}, {'rel': 'no_relation', 'ent1': 'Nuclear Energy Institute', 'ent2': 'Chlorine Chemistry Council', 'text': \"TASSC 's executive director from 1997 to 1998 was Steven Milloy , a Washington policy wonk who has rotated through a variety of anti- environmental organizations as well as the EOP Group , a prominent lobby firm whose clients have included the Petroleum Institute , AT&T , the Business Roundtable , the Chlorine Chemistry Council , Dow Chemical , Edison Electric Institute , International Food Additives Council , Monsanto and the Nuclear Energy Institute .\"}, {'rel': 'no_relation', 'ent1': 'his', 'ent2': 'Marilyn Berger', 'text': 'He is survived by his third wife , former television news correspondent Marilyn Berger ; his sons , Steven and Jeffrey ; his daughter , Lisa Cassara ; his stepdaughter , Jilian Childers Hewitt , whom Hewitt adopted ; and three grandchildren .'}, {'rel': 'no_relation', 'ent1': 'his', 'ent2': 'He', 'text': 'He would strategically enter his horses only in certain races where he could largely predict a successful outcome .'}, {'rel': 'org:top_members/employees', 'ent1': 'Rosoboronexport', 'ent2': 'Sergei Chemezov', 'text': 'Chavez was also due to meet Sergei Chemezov , who oversees Russian arms export monopoly Rosoboronexport , a Kremin source said Tuesday .'}, {'rel': 'no_relation', 'ent1': 'Dixon', 'ent2': '2004', 'text': 'Those charges stem from an accusation that Dixon failed to report gifts on city ethics forms -- cash , travel and clothes -- from Ronald H. Lipscomb , whom Dixon dated in 2003 and 2004 .'}]\n"]}],"source":["train_info = prepare_data(train_data)\n","dev_info = prepare_data(dev_data)\n","test_info = prepare_data(test_data)\n","\n","print(len(train_info))\n","print(len(dev_info))\n","print(len(test_info))\n","print(dev_info[:50])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":159652,"status":"ok","timestamp":1709500096088,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":0},"id":"zpwOfzpzOiEf","outputId":"6c006edb-929f-444a-e4fa-540d9a00cf47"},"outputs":[{"name":"stdout","output_type":"stream","text":["68124\n","22631\n","15509\n"]}],"source":["train_data = process_relation_extraction_data(train_info, 128)\n","dev_data = process_relation_extraction_data(dev_info, 128)\n","test_data = process_relation_extraction_data(test_info, 128)\n","\n","print(len(train_data['label']))\n","print(len(dev_data['label']))\n","print(len(test_data['label']))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5934,"status":"ok","timestamp":1709500102001,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":0},"id":"AR6bEgGCMHDY","outputId":"974c948b-21b2-4efa-f39f-fdc84c87c95b"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-11-846317e3e88f>:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n","  text = torch.tensor(text)\n"]},{"name":"stdout","output_type":"stream","text":["--train data--\n","torch.Size([68124, 1, 128])\n","torch.Size([68124, 1, 128])\n","torch.Size([68124])\n","--eval data--\n","torch.Size([22631, 1, 128])\n","torch.Size([22631, 1, 128])\n","torch.Size([22631])\n","--test data--\n","torch.Size([15509, 1, 128])\n","torch.Size([15509, 1, 128])\n","torch.Size([15509])\n"]}],"source":["# Preprocess train data\n","train_text, train_mask, train_label = convert_data_to_tensors(train_data)\n","print(\"--train data--\")\n","print(train_text.shape)\n","print(train_mask.shape)\n","print(train_label.shape)\n","\n","# Preprocess dev data\n","dev_text, dev_mask, dev_label = convert_data_to_tensors(dev_data)\n","print(\"--eval data--\")\n","print(dev_text.shape)\n","print(dev_mask.shape)\n","print(dev_label.shape)\n","\n","# Preprocess test data\n","test_text, test_mask, test_label = convert_data_to_tensors(test_data)\n","print(\"--test data--\")\n","print(test_text.shape)\n","print(test_mask.shape)\n","print(test_label.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5plRuzg4U_4u"},"outputs":[],"source":["# convert data to tensor\n","train_dataset = torch.utils.data.TensorDataset(train_text,train_mask,train_label)\n","dev_dataset = torch.utils.data.TensorDataset(dev_text,dev_mask,dev_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10440007,"status":"ok","timestamp":1709510542004,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":0},"id":"l-ofVsb7V6O4","outputId":"b0cd238b-02c1-4d21-ec2c-387c886a5129"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/25: 100%|█████████▉| 2128/2129 [06:56<00:00,  5.10batch/s, loss=0.961, accuracy=0.816]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","Loss: 0.9607898592948914, Accuracy: 0.8162006578947368\n","Macro F1: 0.042991175794774406, Micro F1: 0.816200657894737, Weighted F1: 0.7504136402451654\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.578, accuracy=0.849]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/25\n","Loss: 0.5780540704727173, Accuracy: 0.848875117481203\n","Macro F1: 0.1593736053689775, Micro F1: 0.848875117481203, Weighted F1: 0.8140075844145855\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.09batch/s, loss=0.495, accuracy=0.87]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/25\n","Loss: 0.4948521852493286, Accuracy: 0.8695664943609023\n","Macro F1: 0.2991974678051634, Micro F1: 0.8695664943609023, Weighted F1: 0.847681644696828\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.09batch/s, loss=0.483, accuracy=0.886]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/25\n","Loss: 0.4828968346118927, Accuracy: 0.8858670112781954\n","Macro F1: 0.40751585340850405, Micro F1: 0.8858670112781954, Weighted F1: 0.8716257726837299\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.157, accuracy=0.897]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/25\n","Loss: 0.1565702110528946, Accuracy: 0.8968221334586466\n","Macro F1: 0.47765318071103785, Micro F1: 0.8968221334586466, Weighted F1: 0.887036793157364\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/25: 100%|█████████▉| 2128/2129 [06:56<00:00,  5.10batch/s, loss=0.22, accuracy=0.909]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/25\n","Loss: 0.21991120278835297, Accuracy: 0.9089520676691729\n","Macro F1: 0.5563164897171963, Micro F1: 0.9089520676691729, Weighted F1: 0.9020820168025625\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/25: 100%|█████████▉| 2128/2129 [06:56<00:00,  5.10batch/s, loss=0.452, accuracy=0.919]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/25\n","Loss: 0.4520271420478821, Accuracy: 0.9189673402255639\n","Macro F1: 0.6070867789391019, Micro F1: 0.9189673402255639, Weighted F1: 0.9140332552297251\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 8/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.173, accuracy=0.925]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8/25\n","Loss: 0.17298518121242523, Accuracy: 0.9251938439849624\n","Macro F1: 0.6455128540267447, Micro F1: 0.9251938439849624, Weighted F1: 0.9215599589178095\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 9/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.0675, accuracy=0.935]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9/25\n","Loss: 0.06748391687870026, Accuracy: 0.9345189144736842\n","Macro F1: 0.689277786437881, Micro F1: 0.9345189144736842, Weighted F1: 0.9319186568037674\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 10/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.163, accuracy=0.942]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/25\n","Loss: 0.16313813626766205, Accuracy: 0.9415824718045113\n","Macro F1: 0.7240166336322454, Micro F1: 0.9415824718045113, Weighted F1: 0.9396176232717339\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 11/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.0339, accuracy=0.946]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/25\n","Loss: 0.03389120474457741, Accuracy: 0.9455915178571429\n","Macro F1: 0.7411085263887804, Micro F1: 0.9455915178571429, Weighted F1: 0.9440551318556988\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 12/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.35, accuracy=0.95]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/25\n","Loss: 0.34983840584754944, Accuracy: 0.9504816729323309\n","Macro F1: 0.762493183931551, Micro F1: 0.9504816729323309, Weighted F1: 0.9493108806623437\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 13/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.0523, accuracy=0.956]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/25\n","Loss: 0.052301086485385895, Accuracy: 0.9555480498120301\n","Macro F1: 0.780745191164078, Micro F1: 0.9555480498120301, Weighted F1: 0.9546217773542058\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 14/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.0284, accuracy=0.96]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/25\n","Loss: 0.028364714235067368, Accuracy: 0.9597626879699248\n","Macro F1: 0.8039355409864665, Micro F1: 0.9597626879699248, Weighted F1: 0.9591040682494321\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 15/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.585, accuracy=0.925]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/25\n","Loss: 0.5845957398414612, Accuracy: 0.9246211231203008\n","Macro F1: 0.7035475818663597, Micro F1: 0.9246211231203008, Weighted F1: 0.9192074213005988\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 16/25: 100%|█████████▉| 2128/2129 [06:56<00:00,  5.10batch/s, loss=0.141, accuracy=0.812]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/25\n","Loss: 0.1405962109565735, Accuracy: 0.8121475563909775\n","Macro F1: 0.055077616740300685, Micro F1: 0.8121475563909775, Weighted F1: 0.731893959807965\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 17/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.0954, accuracy=0.962]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/25\n","Loss: 0.09538328647613525, Accuracy: 0.961906719924812\n","Macro F1: 0.8188001468651462, Micro F1: 0.961906719924812, Weighted F1: 0.9613602089969682\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 18/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.0803, accuracy=0.969]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/25\n","Loss: 0.08033910393714905, Accuracy: 0.9688674812030075\n","Macro F1: 0.8482022635639632, Micro F1: 0.9688674812030076, Weighted F1: 0.9685709349122799\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 19/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.09batch/s, loss=0.00868, accuracy=0.971]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19/25\n","Loss: 0.00867554172873497, Accuracy: 0.9712171052631579\n","Macro F1: 0.854692244555129, Micro F1: 0.9712171052631579, Weighted F1: 0.9709554648216749\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 20/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.116, accuracy=0.974]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20/25\n","Loss: 0.11571107804775238, Accuracy: 0.9744625234962406\n","Macro F1: 0.8707889587440801, Micro F1: 0.9744625234962406, Weighted F1: 0.974315373751604\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 21/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.183, accuracy=0.974]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21/25\n","Loss: 0.18250255286693573, Accuracy: 0.9739632283834586\n","Macro F1: 0.86757039405117, Micro F1: 0.9739632283834586, Weighted F1: 0.9737878316828819\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 22/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.09batch/s, loss=0.0712, accuracy=0.977]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22/25\n","Loss: 0.07120045274496078, Accuracy: 0.9772086466165414\n","Macro F1: 0.8849673973668505, Micro F1: 0.9772086466165414, Weighted F1: 0.9770735401274018\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 23/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.0134, accuracy=0.978]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 23/25\n","Loss: 0.013353997841477394, Accuracy: 0.9778841635338346\n","Macro F1: 0.8891490004968452, Micro F1: 0.9778841635338346, Weighted F1: 0.9777774464751668\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 24/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.187, accuracy=0.98]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 24/25\n","Loss: 0.18715804815292358, Accuracy: 0.980483435150376\n","Macro F1: 0.89962524133692, Micro F1: 0.980483435150376, Weighted F1: 0.9804073141505946\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 25/25: 100%|█████████▉| 2128/2129 [06:57<00:00,  5.10batch/s, loss=0.0149, accuracy=0.982]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 25/25\n","Loss: 0.014941203407943249, Accuracy: 0.982157542293233\n","Macro F1: 0.9095659174183462, Micro F1: 0.982157542293233, Weighted F1: 0.9820750016021499\n"]}],"source":["train(model, train_dataset, dev_dataset, 25, 0.02, 32)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1495,"status":"ok","timestamp":1709511869631,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":0},"id":"U6hEGxijaokN","outputId":"aa0b24e3-1bd7-43f1-d7bb-3d687613f501"},"outputs":[{"name":"stdout","output_type":"stream","text":["entire Model saved successfully.\n"]}],"source":["torch.save(model, 'span-bert_best_model.pth')\n","print(\"entire Model saved successfully.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttbzHc3_Sm47"},"outputs":[],"source":["import json\n","\n","# grid parameter\n","batch_sizes = [32, 64, 128]\n","learning_rates = [0.02, 0.002, 0.0002]\n","num_epochs = [15, 20, 25]\n","\n","results = []\n","\n","# grid search\n","for batch_size in batch_sizes:\n","    for lr in learning_rates:\n","        for epoch in num_epochs:\n","            print(f\"Training with batch size = {batch_size}, lr = {lr}, epoch = {epoch}\")\n","            # set to initial state\n","            model = BERT_Classifier(labels_num)\n","            # Tell pytorch to run this model on the GPU.\n","            if torch.cuda.is_available():\n","                model.cuda()\n","            # run model\n","            train(model, train_dataset, dev_dataset, epoch, lr, batch_size)\n","\n","            # evaluate the model\n","            test_dataset = torch.utils.data.TensorDataset(test_text, test_mask, test_label)\n","            acc_list, macro_f1_list, micro_f1_list, weighted_f1_list, precision_list, recall_list = eval(model, test_dataset, batch_size)\n","\n","            # save result\n","            result = {\n","                'batch_size': batch_size,\n","                'lr': lr,\n","                'epoch': epoch,\n","                'acc_list': acc_list,\n","                'macro_f1_list': macro_f1_list,\n","                'micro_f1_list': micro_f1_list,\n","                'weighted_f1_list': weighted_f1_list,\n","                'precision_list': precision_list,\n","                'recall_list': recall_list\n","            }\n","            results.append(result)\n","\n","            # save in the file\n","            with open('grid_search_results.txt', 'a') as file:\n","                file.write(json.dumps(result) + '\\n')\n","\n","\n","for result in results:\n","    print(f\"Batch size: {result['batch_size']}, LR: {result['lr']}, Epoch: {result['epoch']}\")\n","    print(f\"Accuracy List: {result['acc_list']}\")\n","    print(f\"Macro F1 List: {result['macro_f1_list']}\")\n","    print(f\"Micro F1 List: {result['micro_f1_list']}\")\n","    print(f\"Weighted F1 List: {result['weighted_f1_list']}\")\n","    print(f\"Precision List: {result['precision_list']}\")\n","    print(f\"Recall List: {result['recall_list']}\")\n","    print(\"--------------------------------------------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LUtasVKAGdXl"},"outputs":[],"source":["# load model \n","model_path = \"/content/Drive/MyDrive/COMP61332_text_mining/RE/Tacred/Bert_RE/inference/span-bert_best_model.pth\"\n","model = torch.load(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54795,"status":"ok","timestamp":1709751219787,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":0},"id":"XQtIP-GYMHDZ","outputId":"63d7f1fa-4742-450d-e1cf-83e986c1c43d"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-11-846317e3e88f>:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n","  text = torch.tensor(text)\n","Evaluation: 100%|█████████▉| 484/485 [00:33<00:00, 14.40batch/s]\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Eval Result: Acc: 0.8910, Macro F1: 0.5591, Micro F1: 0.8910, Weighted F1: 0.8916\n","Precision (Macro, Micro, Weighted): 0.5917, 0.8910, 0.8970\n","Recall (Macro, Micro, Weighted): 0.5990, 0.8910, 0.8910\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["\n","test_data = load_tacred_dataset('/content/Drive/MyDrive/COMP61332_text_mining/RE/Tacred/Bert_RE/experiments/test_rev.json')\n","test_info = prepare_data(test_data)\n","test_data = process_relation_extraction_data(test_info, 128)\n","test_text, test_mask, test_label = convert_data_to_tensors(test_data)\n","test_dataset = torch.utils.data.TensorDataset(test_text, test_mask, test_label)\n","acc_list, macro_f1_list, micro_f1_list, weighted_f1_list, precision_list, recall_list= eval(model, test_dataset, 32)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
